{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riftfound Metrics Dashboard\n",
    "\n",
    "Interactive analysis of site traffic and database statistics.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before running this notebook:\n",
    "\n",
    "1. Download CloudFront logs: `./download-logs.sh 30`\n",
    "2. Install dependencies: `pip install pandas matplotlib`\n",
    "3. For database metrics, ensure `deploy.env` is configured (or use local SQLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "import sqlite3\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "LOGS_DIR = Path('logs')\n",
    "ROOT_DIR = Path('../..')\n",
    "LOCAL_DB = ROOT_DIR / 'data' / 'riftfound.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load CloudFront Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CloudFront log fields\n",
    "FIELDS = [\n",
    "    'date', 'time', 'edge_location', 'bytes', 'client_ip', 'method', 'host',\n",
    "    'uri_stem', 'status', 'referer', 'user_agent', 'query_string', 'cookie',\n",
    "    'edge_result_type', 'request_id', 'host_header', 'protocol', 'cs_bytes',\n",
    "    'time_taken', 'forwarded_for', 'ssl_protocol', 'ssl_cipher',\n",
    "    'edge_response_result_type', 'protocol_version'\n",
    "]\n",
    "\n",
    "def load_cloudfront_logs(logs_dir: Path, days: int = None) -> pd.DataFrame:\n",
    "    \"\"\"Load CloudFront logs into a DataFrame.\"\"\"\n",
    "    records = []\n",
    "    cutoff = None\n",
    "    if days:\n",
    "        cutoff = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    for log_file in logs_dir.glob('*'):\n",
    "        if log_file.suffix == '.gz':\n",
    "            opener = lambda f: gzip.open(f, 'rt', encoding='utf-8', errors='ignore')\n",
    "        elif log_file.is_file() and not log_file.name.startswith('.'):\n",
    "            opener = lambda f: open(f, 'r', encoding='utf-8', errors='ignore')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with opener(log_file) as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('#'):\n",
    "                        continue\n",
    "                    parts = line.strip().split('\\t')\n",
    "                    if len(parts) >= 10:\n",
    "                        if cutoff and parts[0] < cutoff:\n",
    "                            continue\n",
    "                        record = {FIELDS[i]: parts[i] if i < len(parts) else '' \n",
    "                                  for i in range(min(len(FIELDS), len(parts)))}\n",
    "                        records.append(record)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: {log_file}: {e}\")\n",
    "    \n",
    "    df = pd.DataFrame(records)\n",
    "    if not df.empty:\n",
    "        df['datetime'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "        df['bytes'] = pd.to_numeric(df['bytes'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Load logs\n",
    "if LOGS_DIR.exists():\n",
    "    logs_df = load_cloudfront_logs(LOGS_DIR, days=30)\n",
    "    print(f\"Loaded {len(logs_df):,} log records\")\n",
    "    if not logs_df.empty:\n",
    "        print(f\"Date range: {logs_df['date'].min()} to {logs_df['date'].max()}\")\n",
    "else:\n",
    "    print(\"No logs found. Run ./download-logs.sh first.\")\n",
    "    logs_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Traffic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"TRAFFIC SUMMARY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total requests:      {len(logs_df):,}\")\n",
    "    print(f\"Unique visitors:     {logs_df['client_ip'].nunique():,}\")\n",
    "    print(f\"Successful (2xx/3xx): {len(logs_df[logs_df['status'].str.match(r'^[23]')]):,}\")\n",
    "    print(f\"Data transferred:    {logs_df['bytes'].sum() / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"No log data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Daily Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    daily = logs_df.groupby('date').agg(\n",
    "        requests=('date', 'count'),\n",
    "        unique_visitors=('client_ip', 'nunique'),\n",
    "        bytes_transferred=('bytes', 'sum')\n",
    "    ).reset_index()\n",
    "    daily['date'] = pd.to_datetime(daily['date'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Requests\n",
    "    axes[0].bar(daily['date'], daily['requests'], color='steelblue', alpha=0.7)\n",
    "    axes[0].set_ylabel('Requests')\n",
    "    axes[0].set_title('Daily Requests')\n",
    "    \n",
    "    # Unique visitors\n",
    "    axes[1].bar(daily['date'], daily['unique_visitors'], color='seagreen', alpha=0.7)\n",
    "    axes[1].set_ylabel('Unique Visitors')\n",
    "    axes[1].set_title('Daily Unique Visitors (by IP)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary stats\n",
    "    print(f\"\\nAverage daily requests: {daily['requests'].mean():,.0f}\")\n",
    "    print(f\"Average daily visitors: {daily['unique_visitors'].mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Page Views Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    # Categorize requests\n",
    "    def categorize_path(path):\n",
    "        if path in ('/', '/index.html'):\n",
    "            return 'Homepage'\n",
    "        elif re.match(r'^/events?/[a-f0-9-]+$', path):\n",
    "            return 'Event Detail'\n",
    "        elif path == '/api/events':\n",
    "            return 'Calendar API'\n",
    "        elif path.startswith('/api/events/geocode'):\n",
    "            return 'Location Search'\n",
    "        elif path.startswith('/api/'):\n",
    "            return 'Other API'\n",
    "        elif re.match(r'^/assets/', path) or path.endswith(('.js', '.css', '.png', '.ico')):\n",
    "            return 'Static Assets'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    logs_df['category'] = logs_df['uri_stem'].apply(categorize_path)\n",
    "    \n",
    "    # Exclude static assets for page view analysis\n",
    "    pages_df = logs_df[logs_df['category'] != 'Static Assets']\n",
    "    \n",
    "    category_stats = pages_df.groupby('category').agg(\n",
    "        requests=('category', 'count'),\n",
    "        unique_visitors=('client_ip', 'nunique')\n",
    "    ).sort_values('requests', ascending=False)\n",
    "    \n",
    "    print(\"PAGE VIEWS BY CATEGORY\")\n",
    "    print(\"=\" * 50)\n",
    "    print(category_stats.to_string())\n",
    "    \n",
    "    # Pie chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    category_stats['requests'].plot.pie(\n",
    "        autopct='%1.1f%%', \n",
    "        ax=ax,\n",
    "        colors=plt.cm.Set3.colors\n",
    "    )\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title('Request Distribution by Category')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Event Detail Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    event_views = logs_df[logs_df['category'] == 'Event Detail'].copy()\n",
    "    \n",
    "    if not event_views.empty:\n",
    "        print(f\"Total event detail views: {len(event_views):,}\")\n",
    "        print(f\"Unique visitors viewing events: {event_views['client_ip'].nunique():,}\")\n",
    "        print(f\"Unique events viewed: {event_views['uri_stem'].nunique():,}\")\n",
    "        \n",
    "        # Daily event views\n",
    "        daily_events = event_views.groupby('date').size()\n",
    "        \n",
    "        plt.figure(figsize=(14, 5))\n",
    "        daily_events.plot(kind='bar', color='coral', alpha=0.7)\n",
    "        plt.title('Daily Event Detail Page Views')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Views')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Top viewed events\n",
    "        print(\"\\nTop 10 Most Viewed Events:\")\n",
    "        print(event_views['uri_stem'].value_counts().head(10).to_string())\n",
    "    else:\n",
    "        print(\"No event detail views recorded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geographic Distribution (Edge Locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    # CloudFront edge locations indicate approximate user geography\n",
    "    edge_counts = logs_df['edge_location'].value_counts().head(15)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    edge_counts.plot(kind='barh', color='teal', alpha=0.7)\n",
    "    plt.title('Top 15 CloudFront Edge Locations')\n",
    "    plt.xlabel('Requests')\n",
    "    plt.ylabel('Edge Location')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Browser Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not logs_df.empty:\n",
    "    def get_browser(ua):\n",
    "        ua = str(ua).lower()\n",
    "        if 'bot' in ua or 'crawler' in ua or 'spider' in ua:\n",
    "            return 'Bot'\n",
    "        elif 'chrome' in ua and 'edg' not in ua:\n",
    "            return 'Chrome'\n",
    "        elif 'firefox' in ua:\n",
    "            return 'Firefox'\n",
    "        elif 'safari' in ua and 'chrome' not in ua:\n",
    "            return 'Safari'\n",
    "        elif 'edg' in ua:\n",
    "            return 'Edge'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    \n",
    "    logs_df['browser'] = logs_df['user_agent'].apply(get_browser)\n",
    "    browser_counts = logs_df['browser'].value_counts()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    browser_counts.plot.pie(\n",
    "        autopct='%1.1f%%',\n",
    "        ax=ax,\n",
    "        colors=['#4285F4', '#FF7139', '#5FB4CB', '#0078D7', '#888888', '#AAAAAA']\n",
    "    )\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title('Traffic by Browser')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Database Metrics\n",
    "\n",
    "The following cells analyze the SQLite database for event and shop statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_connection():\n",
    "    \"\"\"Get database connection (local SQLite only).\"\"\"\n",
    "    if LOCAL_DB.exists():\n",
    "        return sqlite3.connect(LOCAL_DB)\n",
    "    else:\n",
    "        print(f\"Database not found at {LOCAL_DB}\")\n",
    "        print(\"For production data, run: ./db-metrics.sh --remote\")\n",
    "        return None\n",
    "\n",
    "conn = get_db_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Events & Shops Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    overview = pd.read_sql_query(\"\"\"\n",
    "        SELECT 'Total Events' as metric, COUNT(*) as value FROM events\n",
    "        UNION ALL\n",
    "        SELECT 'Total Shops', COUNT(*) FROM shops\n",
    "        UNION ALL\n",
    "        SELECT 'Events with location', COUNT(*) FROM events WHERE shop_id IS NOT NULL\n",
    "        UNION ALL\n",
    "        SELECT 'Shops with coordinates', COUNT(*) FROM shops WHERE latitude IS NOT NULL\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    print(\"DATABASE OVERVIEW\")\n",
    "    print(\"=\" * 40)\n",
    "    for _, row in overview.iterrows():\n",
    "        print(f\"{row['metric']}: {row['value']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Events Added Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    events_daily = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            date(created_at) as date,\n",
    "            COUNT(*) as events_added\n",
    "        FROM events\n",
    "        WHERE created_at >= date('now', '-30 days')\n",
    "        GROUP BY date(created_at)\n",
    "        ORDER BY date\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if not events_daily.empty:\n",
    "        events_daily['date'] = pd.to_datetime(events_daily['date'])\n",
    "        \n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.bar(events_daily['date'], events_daily['events_added'], color='steelblue', alpha=0.7)\n",
    "        plt.title('Events Added Per Day (Last 30 Days)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Events Added')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nTotal events added (30 days): {events_daily['events_added'].sum():,}\")\n",
    "        print(f\"Average per day: {events_daily['events_added'].mean():.1f}\")\n",
    "    else:\n",
    "        print(\"No events found in the last 30 days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Events by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    event_types = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            COALESCE(event_type, 'Unknown') as event_type,\n",
    "            COUNT(*) as count\n",
    "        FROM events\n",
    "        GROUP BY event_type\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 15\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if not event_types.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.barh(event_types['event_type'], event_types['count'], color='coral', alpha=0.7)\n",
    "        plt.title('Events by Type')\n",
    "        plt.xlabel('Count')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Shops by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    shops_by_state = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            COALESCE(state, 'Unknown') as state,\n",
    "            COUNT(*) as count\n",
    "        FROM shops\n",
    "        WHERE country = 'United States' OR country IS NULL\n",
    "        GROUP BY state\n",
    "        ORDER BY count DESC\n",
    "        LIMIT 20\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if not shops_by_state.empty:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        plt.barh(shops_by_state['state'], shops_by_state['count'], color='seagreen', alpha=0.7)\n",
    "        plt.title('Shops by State (US)')\n",
    "        plt.xlabel('Count')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Recent Scrape Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn:\n",
    "    scrape_runs = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            started_at,\n",
    "            completed_at,\n",
    "            events_found,\n",
    "            events_new,\n",
    "            status\n",
    "        FROM scrape_runs\n",
    "        ORDER BY started_at DESC\n",
    "        LIMIT 15\n",
    "    \"\"\", conn)\n",
    "    \n",
    "    if not scrape_runs.empty:\n",
    "        print(\"RECENT SCRAPE RUNS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(scrape_runs.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No scrape runs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "if conn:\n",
    "    conn.close()\n",
    "    print(\"Database connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
